{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. DEAP Dataset + Asymmetry + SVM\n",
    "\n",
    "In this part 3, we will focus on feature engineering using asymmetry analysis.  Asymmetry analysis here refers to the analysis of imbalance between left and right symmetrical location.\n",
    "\n",
    "Asymmetry analysis is another very basic and must-do analysis for emotions/cognitions/resting state.\n",
    "\n",
    "In this part, we shall extract these asymmetries as features and then input these features into SVM and see if these features are useful for predicting the four valence-arousal classes that we have obtained from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cuda accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset\n",
    "\n",
    "Let's first reuse the dataset loader we have created in Part 1.  *Note that we gonna focus on only the valence dataset for this tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, stim):\n",
    "        _, _, filenames = next(os.walk(path))\n",
    "        filenames = sorted(filenames)\n",
    "        all_data = []\n",
    "        all_label = []\n",
    "        for dat in filenames:\n",
    "            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n",
    "            all_data.append(temp['data'])\n",
    "            \n",
    "            if stim == \"Valence\":\n",
    "                all_label.append(temp['labels'][:,:1])   #the first index is valence\n",
    "            elif stim == \"Arousal\":\n",
    "                all_label.append(temp['labels'][:,1:2]) # Arousal  #the second index is arousal\n",
    "                \n",
    "        self.data = np.vstack(all_data)[:, :32, ]   #shape: (1280, 32, 8064) --> take only the first 32 channels\n",
    "        self.label = np.vstack(all_label) #(1280, )  ==> 1280 samples, each with a unique label (depend on the param \"stim\")\n",
    "        \n",
    "        del temp, all_data, all_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        single_data  = self.data[idx]\n",
    "        single_label = (self.label[idx] > 5).astype(float)   #convert the scale to either 0 or 1 (to classification problem)\n",
    "        \n",
    "        batch = {\n",
    "            'data': torch.Tensor(single_data),\n",
    "            'label': torch.Tensor(single_label)\n",
    "        }\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data\"  #create a folder \"data\", and inside put s01.dat,....,s32.dat inside from the preprocessed folder from the DEAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  torch.Size([1280, 32, 8064])\n",
      "Label shape:  torch.Size([1280, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(path, \"Valence\")\n",
    "\n",
    "data  = dataset[:]['data']\n",
    "label = dataset[:]['label']\n",
    "\n",
    "print(\"Data shape: \" , data.shape)  #1280 = 32 * 40 trials, 32 EEG channels, 8064 samples\n",
    "print(\"Label shape: \", label.shape)  #four classes of LALV, HALV, LAHV, HAHV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look the label distribution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of low valence:  572\n",
      "count of high valence:  708\n"
     ]
    }
   ],
   "source": [
    "lv = label == 0\n",
    "hv = label == 1\n",
    "\n",
    "assert len(label[lv]) + len(label[hv]) == label.shape[0]  #simple unit test\n",
    "print(\"count of low valence: \", len(label[lv]))\n",
    "print(\"count of high valence: \", len(label[hv]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the median of EEG of each group (you can do std on your own exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of low valence 0.009302851\n",
      "Median of high valence 0.0034587365\n"
     ]
    }
   ],
   "source": [
    "lv_unsqueeze = lv.squeeze()\n",
    "hv_unsqueeze = hv.squeeze()\n",
    "\n",
    "print(\"Median of low valence\",  np.median(data[lv_unsqueeze, :, :]))\n",
    "print(\"Median of high valence\", np.median(data[hv_unsqueeze, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Asymmetry Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
