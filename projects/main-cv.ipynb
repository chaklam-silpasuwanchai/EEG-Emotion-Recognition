{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3eab870-2294-405a-b31d-9bfccb5ae4db",
   "metadata": {},
   "source": [
    "# Main 10-Fold Cross-Validation Subject Dependent Split first then Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04369f-de64-426d-8188-c125d9aa4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from components.models import *\n",
    "from components.helper import *\n",
    "from components.dataset_jo import *\n",
    "from components.train import *\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83d369-eb48-4594-b692-c3080f30897d",
   "metadata": {},
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7aef09-9a9d-4a19-ad62-58ed77881a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        LSTM\n",
    "        Conv1D_LSTM\n",
    "        Conv1D_LSTM_Attention\n",
    "        Conv1D_LSTM_SelfAttention\n",
    "        Conv1D_LSTM_MultiHeadSelfAttention\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # set running mode : juypyter or py\n",
    "        # - jupyter = testing mode\n",
    "        # - py      = production mode\n",
    "        parser  = argparse.ArgumentParser()\n",
    "        parser.add_argument('-a', '--model_name',    help='model_name' , type=str, required=False)\n",
    "        parser.add_argument('-x', '--stim',          help='stim' ,       type=int, required=False)\n",
    "        parser.add_argument('-l', '--len_reduction', help='len_reduction' , type=str, required=False)\n",
    "        parser.add_argument('-f', '--isdebug',       help='Set running mode' , type=str, required=False)\n",
    "        args     = parser.parse_args()\n",
    "\n",
    "        if args.isdebug == 'yes' or 'json' in args.isdebug :\n",
    "            print(\"Jupyter mode\")\n",
    "            model_name    = 'LSTM'\n",
    "            stim          = 1\n",
    "            len_reduction = 'mean'  # 'mean'  or 'sum' or 'last'\n",
    "\n",
    "        else:\n",
    "            model_name    = str(args.model_name)\n",
    "            stim          = int(args.stim)\n",
    "            len_reduction = str(args.len_reduction)  # 'none' or 'mean' or 'sum' or 'last'\n",
    "\n",
    "        \n",
    "        \n",
    "               \n",
    "        \n",
    "        ##============================================\n",
    "        #  !!!!!!!!!!!!     DO NOT EDIT BELOW\n",
    "        #============================================\n",
    "        \n",
    "        \n",
    "        self.device = 'cuda:0'\n",
    "\n",
    "        #========== Training Configurations==========\n",
    "        self.path = \"../data\" \n",
    "        \n",
    "        \n",
    "        # STIMULI_VALENCE = 0\n",
    "        # STIMULI_AROUSAL = 1       \n",
    "        self.stim      = stim\n",
    "        self.stim_name = 'VALENCE' if self.stim else 'AROUSAL'\n",
    "\n",
    "        self.params     = {\"batch_size\" : 16, \"shuffle\" : True, \"pin_memory\" : True}\n",
    "        self.num_epochs = 50\n",
    "        self.lr         = 0.0001\n",
    "\n",
    "        # true only if using 'LSTM'\n",
    "        if model_name == 'LSTM' :\n",
    "            self.seq_len_first = True\n",
    "        else :\n",
    "            self.seq_len_first = False\n",
    "\n",
    "        self.debug = False\n",
    "        if self.debug:\n",
    "            self.num_epochs = 1\n",
    "            self.n_split    = 3\n",
    "\n",
    "        #========== Model Configurations==========\n",
    "        # model list \n",
    "\n",
    "        \n",
    "        \n",
    "        self.model_name    = model_name   # this should be match with the model class\n",
    "        self.input_dim     = 32   # we got 32 EEG channels\n",
    "        self.hidden_dim    = 256  # let's define hidden dim as 256\n",
    "        self.num_layers    = 2    # we gonna have two LSTM layers\n",
    "        self.output_dim    = 1    # we got 2 classes so we can output only 1 number, 0 for first class and 1 for another class\n",
    "        self.bidirectional = True # uses bidirectional LSTM\n",
    "        self.dropout       = 0.5  # setting dropout to 0.5\n",
    "\n",
    "        # for self attention\n",
    "        self.len_reduction = len_reduction\n",
    "\n",
    "        # for multi head attention\n",
    "        self.n_heads       = 8\n",
    "        self.d_k           = (self.hidden_dim * 2) // self.n_heads # (256 * 2) // 8\n",
    "        \n",
    "        \n",
    "        #========== save config ==========\n",
    "        self.output_path   = 'output/'\n",
    "        self.result_csv    = f'{self.output_path}{self.model_name}_result.csv'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef506e0a-ea2f-4e6b-8730-71856a931eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "print_cls_var( config )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2fb70-7d34-4f9d-8e99-2c6a755c2624",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c582275-b1ec-4d0f-9fde-bc9117ce3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def init_model( config ):\n",
    "    \n",
    "    if config.model_name == 'LSTM' :\n",
    "        model = LSTM( config.input_dim, \n",
    "                     config.hidden_dim, \n",
    "                     config.num_layers, \n",
    "                     config.output_dim, \n",
    "                     config.bidirectional, \n",
    "                     config.dropout)\n",
    "        \n",
    "    elif config.model_name == 'Conv1D_LSTM' :\n",
    "        model = Conv1D_LSTM( config.input_dim, \n",
    "                            config.hidden_dim, \n",
    "                            config.num_layers, \n",
    "                            config.output_dim, \n",
    "                            config.bidirectional, \n",
    "                            config.dropout\n",
    "                           )\n",
    "    elif config.model_name == 'Conv1D_LSTM_Attention' :\n",
    "        model = Conv1D_LSTM_Attention ( config.input_dim, \n",
    "                                       config.hidden_dim, \n",
    "                                       config.num_layers, \n",
    "                                       config.output_dim, \n",
    "                                       config.bidirectional, \n",
    "                                       config.dropout\n",
    "                                      )\n",
    "\n",
    "    elif config.model_name == 'Conv1D_LSTM_SelfAttention' :\n",
    "        model = Conv1D_LSTM_SelfAttention( config.input_dim, \n",
    "                                  config.hidden_dim, \n",
    "                                  config.num_layers, \n",
    "                                  config.output_dim, \n",
    "                                  config.bidirectional, \n",
    "                                  config.dropout, \n",
    "                                  config.len_reduction   \n",
    "                                 )\n",
    "    elif config.model_name == 'Conv1D_LSTM_MultiHeadSelfAttention' :\n",
    "        model =Conv1D_LSTM_MultiHeadSelfAttention( config.input_dim, \n",
    "                                                  config.hidden_dim, \n",
    "                                                  config.num_layers, \n",
    "                                                  config.output_dim, \n",
    "                                                  config.bidirectional, \n",
    "                                                  config.dropout, \n",
    "                                                  config.len_reduction,\n",
    "                                                  config.n_heads,\n",
    "                                                  config.d_k\n",
    "                                                 )\n",
    "    \n",
    "    \n",
    "    model = model.to(config.device)  \n",
    "    model.apply(initialize_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr) \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    \n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90c946-f9b4-44ff-940d-6d8e0e317a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, _, _ = init_model( config )\n",
    "print(f'The model {type(model).__name__} has {count_parameters(model):,} trainable parameters')# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98ed7c-c5e2-41a4-babe-464acec8aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_subjectDependent(config.path)\n",
    "dataset.set_segment(60)\n",
    "\n",
    "filenames = dataset.get_file_list()\n",
    "filenames.sort()\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a316d-8455-41f6-b438-bff439fec426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reset_model():\n",
    "#     model = LSTM(input_dim, hidden_dim, num_layers, output_dim, bidirectional, dropout)\n",
    "#     model = model.to(device)  \n",
    "#     model.apply(initialize_weights)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr) \n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "#     return model, optimizer, criterion\n",
    "\n",
    "def make_dataloader(X_orig, y_orig, train_idxs, test_idxs, params):\n",
    "    \n",
    "    X_train, X_test = X_orig[train_idxs] , X_orig[test_idxs]\n",
    "    y_train, y_test = y_orig[train_idxs] , y_orig[test_idxs]\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\n",
    "    test_dataset  = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
    "    del X_train, X_test, y_train, y_test\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, **params)\n",
    "    val_loader   = DataLoader(test_dataset, **params)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7c701-0cbe-41d0-8043-ce32ef68ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for filename in filenames:\n",
    "    print(\"==================================================\")\n",
    "    print(\"Participant : \", filename )\n",
    "    result_dict[filename] = {}\n",
    "    \n",
    "    \n",
    "    # get participant dataset\n",
    "    X, y, groups = dataset.get_data(filename, Dataset_subjectDependent.STIMULI_AROUSAL, return_type='numpy')\n",
    "    print(filename, X.shape, y.squeeze().shape, groups.shape)\n",
    "\n",
    "    cv = GroupShuffleSplit(n_splits=10, train_size=0.75, random_state=0)\n",
    "    \n",
    "    # get each fold for training and testing model\n",
    "\n",
    "    for fold, ( train_idxs, test_idxs ) in enumerate( cv.split(X, y.squeeze(), groups)):\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print( \"fold : \", fold )\n",
    "        print(train_idxs.shape, test_idxs.shape, set(groups[train_idxs]).intersection(groups[test_idxs]) )\n",
    "        \n",
    "\n",
    "        X_orig, y_orig = X.copy(), y.copy()\n",
    "        train_loader, val_loader = make_dataloader(X_orig, y_orig, train_idxs, test_idxs, config.params)\n",
    "        \n",
    "        # === Init MODEL ===\n",
    "        model, optimizer, criterion = init_model( config )\n",
    "        \n",
    "        # === DO TRAINING === \n",
    "        train_loss, valid_loss, train_acc , valid_acc , epoch_times = train(config.num_epochs,\n",
    "                                                             model,\n",
    "                                                             train_loader,\n",
    "                                                             val_loader,\n",
    "                                                             optimizer,\n",
    "                                                             criterion,\n",
    "                                                             config.device,\n",
    "                                                              config.seq_len_first)\n",
    "        \n",
    "        del model, optimizer, criterion, train_loader, val_loader\n",
    "\n",
    "        ## save to csv at specific epoch\n",
    "        for epoch in range( config.num_epochs ) :\n",
    "                result_csv_dic               = {}\n",
    "                result_csv_dic['len_reduction']  =  config.len_reduction\n",
    "                result_csv_dic['par']        =  filename\n",
    "                result_csv_dic['stim_name']  =  config.stim_name\n",
    "                result_csv_dic['fold']       =  fold\n",
    "                result_csv_dic['epoch']      =  epoch\n",
    "                result_csv_dic['train_loss'] = train_loss[epoch]\n",
    "                result_csv_dic['valid_loss'] = valid_loss[epoch]\n",
    "                result_csv_dic['train_acc']  = train_acc[epoch]\n",
    "                result_csv_dic['valid_acc']  = valid_acc[epoch]\n",
    "                result_csv_dic['epoch_time'] = epoch_times[epoch]\n",
    "                save_result_csv( result_csv_dic, config.result_csv )\n",
    "                \n",
    "            \n",
    "        # ## save dictionary of all output result\n",
    "        # result_dict[filename][fold]['train_loss'].append(train_loss)\n",
    "        # result_dict[filename][fold]['train_acc'].append(train_acc)\n",
    "        # result_dict[filename][fold]['valid_loss'].append(valid_loss)\n",
    "        # result_dict[filename][fold]['valid_acc'].append(valid_acc)\n",
    "        # result_dict[filename][fold]['epoch_mins'].append(epoch_mins)\n",
    "        # result_dict[filename][fold]['epoch_secs'].append(epoch_secs)      \n",
    "        # with open(f'{config.output_path}{config.model_name}_{config.stim_name}_output_dic', 'wb') as outp:\n",
    "        #     pickle.dump(result_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jakrapop_nlu",
   "language": "python",
   "name": "jakrapop_nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
