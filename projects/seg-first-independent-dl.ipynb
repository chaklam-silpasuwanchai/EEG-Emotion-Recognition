{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3eab870-2294-405a-b31d-9bfccb5ae4db",
   "metadata": {},
   "source": [
    "# Subject Independent\n",
    "# Segment first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb04369f-de64-426d-8188-c125d9aa4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from components.models import *\n",
    "from components.helper import *\n",
    "from components.dataset import *\n",
    "from components.train import *\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83d369-eb48-4594-b692-c3080f30897d",
   "metadata": {},
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7aef09-9a9d-4a19-ad62-58ed77881a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        LSTM\n",
    "        Conv1D_LSTM\n",
    "        Conv1D_LSTM_Attention\n",
    "        Conv1D_LSTM_SelfAttention\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # set running mode : juypyter or py\n",
    "        # - jupyter = testing mode\n",
    "        # - py      = production mode\n",
    "        parser  = argparse.ArgumentParser()\n",
    "        parser.add_argument('-a', '--model_name',     help='model_name' , type=str, required=False)\n",
    "        parser.add_argument('-x', '--stim',           help='stim'       , type=int, required=False)\n",
    "        parser.add_argument('-s', '--segment_number', help='segment_number'    , type=int, required=False)\n",
    "        parser.add_argument('-l', '--len_reduction',  help='len_reduction' , type=str, required=False)\n",
    "        parser.add_argument('-f', '--isdebug',        help='Set running mode' , type=str, required=False)\n",
    "        args     = parser.parse_args()\n",
    "\n",
    "        if args.isdebug == 'yes' or 'json' in args.isdebug :\n",
    "            print(\"Jupyter mode\")\n",
    "            model_name     = 'LSTM'\n",
    "            stim           = 1\n",
    "            len_reduction  = 'mean'  # 'mean'  or 'sum' or 'last'\n",
    "            segment_number = 1 # 1, 3, 5, 60\n",
    "\n",
    "        else:\n",
    "            model_name     = str(args.model_name)\n",
    "            stim           = int(args.stim)\n",
    "            segment_number = int(args.segment_number)\n",
    "            len_reduction  = str(args.len_reduction)  # 'none' or 'mean' or 'sum' or 'last'\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "               \n",
    "        \n",
    "        ##============================================\n",
    "        #  !!!!!!!!!!!!     DO NOT EDIT BELOW\n",
    "        #============================================\n",
    "        \n",
    "        \n",
    "        self.device = get_freer_gpu()\n",
    "\n",
    "        #========== Training Configurations==========\n",
    "        self.path = \"./data\" \n",
    "        \n",
    "        \n",
    "        # STIMULI_VALENCE = 0\n",
    "        # STIMULI_AROUSAL = 1       \n",
    "        self.stim      = stim\n",
    "        self.stim_name = 'AROUSAL' if self.stim else 'VALENCE'\n",
    "        self.segment_number   = segment_number\n",
    "\n",
    "        self.params     = {\"batch_size\" : 16, \"shuffle\" : True, \"pin_memory\" : True}\n",
    "        self.num_epochs = 30\n",
    "        self.lr         = 0.0001\n",
    "\n",
    "        # true only if using 'LSTM'\n",
    "        if model_name == 'LSTM' :\n",
    "            self.seq_len_first = True\n",
    "        else :\n",
    "            self.seq_len_first = False\n",
    "\n",
    "        self.debug = False\n",
    "        if self.debug:\n",
    "            self.num_epochs = 1\n",
    "            self.n_split    = 3\n",
    "\n",
    "        #========== Model Configurations==========\n",
    "        # model list \n",
    "\n",
    "        \n",
    "        \n",
    "        self.model_name    = model_name   # this should be match with the model class\n",
    "        self.input_dim     = 32   # we got 32 EEG channels\n",
    "        self.hidden_dim    = 256  # let's define hidden dim as 256\n",
    "        self.num_layers    = 2    # we gonna have two LSTM layers\n",
    "        self.output_dim    = 1    # we got 2 classes so we can output only 1 number, 0 for first class and 1 for another class\n",
    "        self.bidirectional = True # uses bidirectional LSTM\n",
    "        self.dropout       = 0.5  # setting dropout to 0.5\n",
    "\n",
    "        # for self attention\n",
    "        self.len_reduction = len_reduction\n",
    "\n",
    "        # for multi head attention\n",
    "        self.n_heads       = 8\n",
    "        self.d_k           = (self.hidden_dim * 2) // self.n_heads # (256 * 2) // 8\n",
    "        \n",
    "        if self.model_name == 'CNN2D' :\n",
    "            if self.segment_number == 1:\n",
    "                self.fc_shape = 237568\n",
    "            if self.segment_number == 3:\n",
    "                self.fc_shape = 73728\n",
    "            if self.segment_number == 5:\n",
    "                self.fc_shape = 40960\n",
    "            if self.segment_number == 60:\n",
    "                self.fc_shape = 2048\n",
    "        \n",
    "        \n",
    "        #========== save config ==========\n",
    "        self.segsplit      = 'independent-seg'\n",
    "        self.output_path   = f'./output/{self.segsplit}_{int(60/self.segment_number)}s/'\n",
    "        if args.isdebug == 'yes' or 'json' in args.isdebug :\n",
    "            self.result_csv    = f'{self.output_path}tmp_{self.model_name}_result.csv'\n",
    "        else:\n",
    "            self.result_csv    = f'{self.output_path}{self.model_name}_result.csv'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef506e0a-ea2f-4e6b-8730-71856a931eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-a MODEL_NAME] [-x STIM]\n",
      "                             [-s SEGMENT_NUMBER] [-l LEN_REDUCTION]\n",
      "                             [-f ISDEBUG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9021 --control=9019 --hb=9018 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"9bc104e2-b728-4027-91d9-c17c0b10f236\" --shell=9020 --transport=\"tcp\" --iopub=9022 --f=/root/.local/share/jupyter/runtime/kernel-v2-2599GdOlNPaVvnd.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print_cls_var( config )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2fb70-7d34-4f9d-8e99-2c6a755c2624",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c582275-b1ec-4d0f-9fde-bc9117ce3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model( config ):\n",
    "    \n",
    "    if config.model_name == 'LSTM' :\n",
    "        model = LSTM( config.input_dim, \n",
    "                     config.hidden_dim, \n",
    "                     config.num_layers, \n",
    "                     config.output_dim, \n",
    "                     config.bidirectional, \n",
    "                     config.dropout)\n",
    "        \n",
    "    elif config.model_name == 'Conv1D_LSTM' :\n",
    "        model = Conv1D_LSTM( config.input_dim, \n",
    "                            config.hidden_dim, \n",
    "                            config.num_layers, \n",
    "                            config.output_dim, \n",
    "                            config.bidirectional, \n",
    "                            config.dropout\n",
    "                           )\n",
    "    elif config.model_name == 'Conv1D_LSTM_Attention' :\n",
    "        model = Conv1D_LSTM_Attention ( config.input_dim, \n",
    "                                       config.hidden_dim, \n",
    "                                       config.num_layers, \n",
    "                                       config.output_dim, \n",
    "                                       config.bidirectional, \n",
    "                                       config.dropout\n",
    "                                      )\n",
    "\n",
    "    elif config.model_name == 'Conv1D_LSTM_SelfAttention' :\n",
    "        model = Conv1D_LSTM_SelfAttention( config.input_dim, \n",
    "                                  config.hidden_dim, \n",
    "                                  config.num_layers, \n",
    "                                  config.output_dim, \n",
    "                                  config.bidirectional, \n",
    "                                  config.dropout, \n",
    "                                  config.len_reduction   \n",
    "                                 )\n",
    "    elif config.model_name == 'Conv1D_LSTM_MultiHeadSelfAttention' :\n",
    "        model =Conv1D_LSTM_MultiHeadSelfAttention( config.input_dim, \n",
    "                                                  config.hidden_dim, \n",
    "                                                  config.num_layers, \n",
    "                                                  config.output_dim, \n",
    "                                                  config.bidirectional, \n",
    "                                                  config.dropout, \n",
    "                                                  config.len_reduction,\n",
    "                                                  config.n_heads,\n",
    "                                                  config.d_k\n",
    "                                                 )\n",
    "    elif config.model_name == 'CNN2D' :\n",
    "        model = CNN2D( config.input_dim, \n",
    "                       config.output_dim,\n",
    "                      config.fc_shape \n",
    "                      \n",
    "                    )\n",
    "    \n",
    "    \n",
    "    model = model.to(config.device)  \n",
    "    model.apply(initialize_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr) \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    \n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90c946-f9b4-44ff-940d-6d8e0e317a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model LSTM has 2,171,393 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model, _, _ = init_model( config )\n",
    "print(f'The model {type(model).__name__} has {count_parameters(model):,} trainable parameters')# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98ed7c-c5e2-41a4-babe-464acec8aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 32 files\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetDEAP(config.path)\n",
    "dataset.set_segment(config.segment_number)\n",
    "\n",
    "filenames = dataset.get_file_list()\n",
    "filenames.sort()\n",
    "# print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a316d-8455-41f6-b438-bff439fec426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dataloader(X_orig, y_orig, trainval_idxs, test_idxs, params):\n",
    "    \n",
    "#     train_num = int(len(trainval_idxs)*0.75)\n",
    "#     # print(train_num, len(trainval_idxs))\n",
    "    \n",
    "#     random.shuffle(trainval_idxs)\n",
    "#     train_idxs = trainval_idxs[:train_num]\n",
    "#     val_idxs   = trainval_idxs[train_num:]\n",
    "    \n",
    "#     assert [i for i in train_idxs if i in val_idxs] == []\n",
    "    \n",
    "#     X_train, X_val, X_test = X_orig[train_idxs], X_orig[val_idxs], X_orig[test_idxs]\n",
    "#     y_train, y_val, y_test = y_orig[train_idxs], y_orig[val_idxs], y_orig[test_idxs]\n",
    "\n",
    "#     train_dataset = TensorDataset(torch.tensor(X_train).float() , torch.tensor(y_train).float())\n",
    "#     val_dataset   = TensorDataset(torch.tensor(X_val).float()   , torch.tensor(y_val).float())\n",
    "#     test_dataset  = TensorDataset(torch.tensor(X_test).float()  , torch.tensor(y_test).float())\n",
    "#     del X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \n",
    "#     print(\"len(train_dataset)\", len(train_dataset))\n",
    "#     print(\"len(val_dataset)  \", len(val_dataset))\n",
    "#     print(\"len(test_dataset) \", len(test_dataset))\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, **params)\n",
    "#     val_loader   = DataLoader(val_dataset  , **params)\n",
    "#     test_loader  = DataLoader(test_dataset , **params)\n",
    "    \n",
    "#     # print(\"len(train_loader)\", len(train_loader))\n",
    "#     # print(\"len(val_loader)  \", len(val_loader))\n",
    "#     # print(\"len(test_loader) \", len(test_loader))\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7c701-0cbe-41d0-8043-ce32ef68ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_655/3249138814.py\", line 44, in <module>\n",
      "    train_loss, valid_loss, train_acc , valid_acc , test_loss, test_acc, best_epoch, epoch_times = train(config.num_epochs,\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 18, in train\n",
      "    train_loss, train_acc    = _train(model, train_loader, optimizer, criterion, device, seq_len_first)\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 68, in _train\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 392, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 426, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_655/3249138814.py\", line 44, in <module>\n",
      "    train_loss, valid_loss, train_acc , valid_acc , test_loss, test_acc, best_epoch, epoch_times = train(config.num_epochs,\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 18, in train\n",
      "    train_loss, train_acc    = _train(model, train_loader, optimizer, criterion, device, seq_len_first)\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 68, in _train\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 746, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_655/3249138814.py\", line 44, in <module>\n",
      "    train_loss, valid_loss, train_acc , valid_acc , test_loss, test_acc, best_epoch, epoch_times = train(config.num_epochs,\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 18, in train\n",
      "    train_loss, train_acc    = _train(model, train_loader, optimizer, criterion, device, seq_len_first)\n",
      "  File \"/home/st121395/work/EEG-Emotion-Recognition/components/train.py\", line 68, in _train\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 392, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 426, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "all_test_acc = []\n",
    "\n",
    "# get each participant dataset\n",
    "if config.model_name == 'CNN2D':\n",
    "    print(\"Getting spectrogram data ... \")\n",
    "    X, y, _ = dataset.get_all_spec_data( config.stim)\n",
    "else : \n",
    "    X, y, _ = dataset.get_all_data( config.stim, return_type='numpy')\n",
    "# print(X.shape, y.squeeze().shape)\n",
    "\n",
    "cv_outer = StratifiedKFold( n_splits = 10 )\n",
    "X_orig, y_orig = X.copy(), y.copy()\n",
    "\n",
    "for outer_fold, ( trainval_idxs, test_idxs ) in enumerate( cv_outer.split(X, y.squeeze())):\n",
    "\n",
    "#     print( \"Outer Fold : \", outer_fold )\n",
    "#     print(trainval_idxs.shape, test_idxs.shape )\n",
    "    \n",
    "    X_trainval, X_test = X_orig[trainval_idxs], X_orig[test_idxs]\n",
    "    y_trainval, y_test = y_orig[trainval_idxs], y_orig[test_idxs]\n",
    "\n",
    "    test_dataset  = TensorDataset(torch.tensor(X_test).float()  , torch.tensor(y_test).float())\n",
    "    test_loader   = DataLoader(test_dataset , **config.params)\n",
    "    \n",
    "    cv_inner = ShuffleSplit( n_splits = 1 , train_size = 0.8, random_state = 42 )\n",
    "    \n",
    "    for inner_fold, ( train_idxs, val_idxs ) in enumerate( cv_inner.split(X_trainval, y_trainval.squeeze())):\n",
    "        \n",
    "        # print( \"Inner Fold : \", inner_fold )\n",
    "        # print(train_idxs.shape, val_idxs.shape )\n",
    "\n",
    "        X_train, X_val = X_trainval[train_idxs], X_trainval[val_idxs]\n",
    "        y_train, y_val = y_trainval[train_idxs], y_trainval[val_idxs]\n",
    "\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train).float() , torch.tensor(y_train).float())\n",
    "        val_dataset   = TensorDataset(torch.tensor(X_val).float()   , torch.tensor(y_val).float())\n",
    "        train_loader  = DataLoader(val_dataset  , **config.params)\n",
    "        val_loader    = DataLoader(test_dataset , **config.params)\n",
    "\n",
    "        # === Init MODEL ===\n",
    "        model, optimizer, criterion = init_model( config )\n",
    "\n",
    "        # === DO TRAINING === \n",
    "        train_loss, valid_loss, train_acc , valid_acc , test_loss, test_acc, best_epoch, epoch_times = train(config.num_epochs,\n",
    "                                                                                                 model,\n",
    "                                                                                                 train_loader,\n",
    "                                                                                                 val_loader,\n",
    "                                                                                                 test_loader,\n",
    "                                                                                                 optimizer,\n",
    "                                                                                                 criterion,\n",
    "                                                                                                 config.device,\n",
    "                                                                                                 config.seq_len_first)\n",
    "\n",
    "        all_test_acc.append(test_acc)\n",
    "        del model, optimizer, criterion, train_loader, val_loader\n",
    "\n",
    "        # save to csv at specific epoch\n",
    "        for epoch in range( best_epoch + 1 ) :\n",
    "                result_csv_dic               = {}\n",
    "                result_csv_dic['segment_number'] =  config.segment_number\n",
    "                result_csv_dic['len_reduction']  =  config.len_reduction\n",
    "                result_csv_dic['par']            =  'all'\n",
    "                result_csv_dic['stim_name']      =  config.stim_name\n",
    "                result_csv_dic['fold']     =  outer_fold\n",
    "                result_csv_dic['epoch']          =  epoch\n",
    "                result_csv_dic['train_loss']     =  train_loss[epoch]\n",
    "                result_csv_dic['valid_loss']     =  valid_loss[epoch]\n",
    "                result_csv_dic['train_acc']      =  train_acc[epoch]\n",
    "                result_csv_dic['valid_acc']      =  valid_acc[epoch]\n",
    "                result_csv_dic['epoch_times']    =  epoch_times[epoch]\n",
    "\n",
    "                if epoch == best_epoch:\n",
    "                    result_csv_dic['test_loss']  =  test_loss\n",
    "                    result_csv_dic['test_acc']   =  test_acc\n",
    "                else:\n",
    "                    result_csv_dic['test_loss']  =  ''\n",
    "                    result_csv_dic['test_acc']   =  ''\n",
    "\n",
    "                save_result_csv( result_csv_dic, config.result_csv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "segsplit       independent-seg\n",
      "model_name     LSTM\n",
      "stim_name      AROUSAL\n",
      "segment size   60 s\n",
      "all_test_acc :  []\n",
      "AVG all_test_acc :  nan\n",
      "ERROR! Session/line number was not unique inSD  all_test_acc :  nan\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " database. History logging moved to new session 12\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"segsplit      \", config.segsplit)\n",
    "print(\"model_name    \", config.model_name)\n",
    "print(\"stim_name     \", config.stim_name)\n",
    "print(\"segment size  \", int(60/config.segment_number), 's')\n",
    "\n",
    "print(\"all_test_acc : \", all_test_acc)\n",
    "print(\"AVG all_test_acc : \", np.mean(all_test_acc))\n",
    "print(\"SD  all_test_acc : \", np.std(all_test_acc))\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b4a57-abd2-42ee-b172-3cee076e952c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc64ea-9aef-4ee3-8965-4c3b64e2e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_num = 1 : (40, 32, 119, 65)\n",
    "# seg_num = 3 : (120, 32, 39, 65)\n",
    "# seg_num = 5 : (200, 32, 23, 65)\n",
    "# seg_num = 60 : (2400, 32, 31, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "27768773b483d82a9b2b839e3fa80b1be5789db7fd78df4eedef2df266871616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
