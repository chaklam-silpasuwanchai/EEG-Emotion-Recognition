{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. DEAP Dataset + Common Spatial Pattern + SVM\n",
    "\n",
    "In this part 5, we will focus on performing feature engineering using common spatial pattern analysis.  Common spatial pattern is about separating signals into additive composed components that has the maximium differences in variances.\n",
    "\n",
    "Common spatial pattern is a very common dimensionality reduction techniques done on EEG signals.  The main difference between CSP and LDA is that CSP does not look at mean.  On the other hand, CSP is extremely similar to PCA (Principle Component Analysis) because it also employs eigenvalue decompositions but the slight difference is that CSP is done on two different signal windows thus you can say that CSP is a PCA made specificially for signals.\n",
    "\n",
    "In this part, we shall extract common spatial patterns as features.  Lastly, let's try input the features into SVM and see if these features are useful for predicting the four valence-arousal classes that we have obtained from Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd3936",
   "metadata": {},
   "source": [
    "[Youtube - Lecture 7.3 Common Spatial Patterns](https://www.youtube.com/watch?v=zsOULC16USU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset\n",
    "\n",
    "By the time I reach this tutorial, the class Dataset is gone. Therefore, I will load the data from my cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (15360, 32, 672)\n",
      "Label shape:  (15360,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Here I can load the data from cache (work a bit faster than loop through the /data/*.dat)\n",
    "def save(data,filename):\n",
    "    with open(f'cache/{filename}.pickle', 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(filename):\n",
    "    with open(f'cache/{filename}.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load('data_valence')\n",
    "label = load('label_valence')\n",
    "\n",
    "print(\"Data shape: \" , data.shape)  #15360 = 32 * 40 trials * 12 segments, 32 EEG channels, 672 samples\n",
    "print(\"Label shape: \", label.shape)  #two classes of valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Spatial Pattern\n",
    "\n",
    "For this technique, we are not going to code from scratch. Hooray!!!\n",
    "\n",
    "The `mne` library already provide us a function to use.\n",
    "\n",
    "- [Decoding in time-frequency space using Common Spatial Patterns (CSP)](https://mne.tools/stable/auto_examples/decoding/decoding_csp_timefreq.html)\n",
    "- [Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)](https://mne.tools/stable/auto_examples/decoding/decoding_csp_eeg.html)\n",
    "\n",
    "The API\n",
    "\n",
    "- [mne.decoding.CSP](https://mne.tools/stable/generated/mne.decoding.CSP.html)\n",
    "\n",
    "In quick, `mne.decoding.CSP` is a class and its usage is like sklearn class. (The `<obj>.fit_transform(x,y)`)\n",
    "\n",
    "The key different between CSP and PCA is that the PCA only maximized the variance while CSP maximized the variance **based on label**\n",
    "\n",
    "In the argument of `fit_transform`, `x` is your SVM ready data (n_samples, n_features) and `y` is the label (n_samples,)\n",
    "\n",
    "Let's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8bb5afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9e+03 (2.2e-16 eps * 32 dim * 2.6e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.7e+03 (2.2e-16 eps * 32 dim * 2.4e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "The leading minor of order 32 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmne\u001b[39;00m\n\u001b[1;32m      2\u001b[0m csp \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mdecoding\u001b[39m.\u001b[39mCSP(n_components\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, transform_into\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maverage_power\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m csp_data \u001b[39m=\u001b[39m csp\u001b[39m.\u001b[39;49mfit_transform(data\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64),label)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(csp_data), csp_data\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py:236\u001b[0m, in \u001b[0;36mCSP.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=233'>234</a>\u001b[0m \u001b[39m@copy_doc\u001b[39m(TransformerMixin\u001b[39m.\u001b[39mfit_transform)\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=234'>235</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):  \u001b[39m# noqa: D102\u001b[39;00m\n\u001b[0;32m--> <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=235'>236</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(X, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m~/projects/.venv/lib/python3.8/site-packages/mne/decoding/mixin.py:33\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/mixin.py?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m     <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/mixin.py?line=30'>31</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/mixin.py?line=31'>32</a>\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m---> <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/mixin.py?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py:176\u001b[0m, in \u001b[0;36mCSP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=169'>170</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcomponent_order=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malternate\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires two \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=170'>171</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mclasses, but data contains \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m classes; use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=171'>172</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mcomponent_order=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmutual_info\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=172'>173</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39minstead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_classes))\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=174'>175</a>\u001b[0m covs, sample_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_covariance_matrices(X, y)\n\u001b[0;32m--> <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=175'>176</a>\u001b[0m eigen_vectors, eigen_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompose_covs(covs,\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=176'>177</a>\u001b[0m                                                    sample_weights)\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=177'>178</a>\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_order_components(covs, sample_weights, eigen_vectors,\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=178'>179</a>\u001b[0m                             eigen_values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_order)\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=180'>181</a>\u001b[0m eigen_vectors \u001b[39m=\u001b[39m eigen_vectors[:, ix]\n",
      "File \u001b[0;32m~/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py:535\u001b[0m, in \u001b[0;36mCSP._decompose_covs\u001b[0;34m(self, covs, sample_weights)\u001b[0m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=532'>533</a>\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(covs)\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=533'>534</a>\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=534'>535</a>\u001b[0m     eigen_values, eigen_vectors \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49meigh(covs[\u001b[39m0\u001b[39;49m], covs\u001b[39m.\u001b[39;49msum(\u001b[39m0\u001b[39;49m))\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=535'>536</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=536'>537</a>\u001b[0m     \u001b[39m# The multiclass case is adapted from\u001b[39;00m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=537'>538</a>\u001b[0m     \u001b[39m# http://github.com/alexandrebarachant/pyRiemann\u001b[39;00m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/mne/decoding/csp.py?line=538'>539</a>\u001b[0m     eigen_vectors, D \u001b[39m=\u001b[39m _ajd_pham(covs)\n",
      "File \u001b[0;32m~/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py:580\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=576'>577</a>\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m'\u001b[39m\u001b[39mIllegal value in argument \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m of internal \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=577'>578</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m-\u001b[39minfo, drv\u001b[39m.\u001b[39mtypecode \u001b[39m+\u001b[39m pfx \u001b[39m+\u001b[39m driver))\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=578'>579</a>\u001b[0m \u001b[39melif\u001b[39;00m info \u001b[39m>\u001b[39m n:\n\u001b[0;32m--> <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=579'>580</a>\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m'\u001b[39m\u001b[39mThe leading minor of order \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m of B is not \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=580'>581</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mpositive definite. The factorization of B \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=581'>582</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mcould not be completed and no eigenvalues \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=582'>583</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mor eigenvectors were computed.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(info\u001b[39m-\u001b[39mn))\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=584'>585</a>\u001b[0m     drv_err \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mev\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mThe algorithm failed to converge; \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=585'>586</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39moff-diagonal elements of an intermediate \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=586'>587</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mtridiagonal form did not converge to zero.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=591'>592</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mevr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mInternal Error.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///root/projects/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py?line=592'>593</a>\u001b[0m                }\n",
      "\u001b[0;31mLinAlgError\u001b[0m: The leading minor of order 32 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed."
     ]
    }
   ],
   "source": [
    "import mne\n",
    "csp = mne.decoding.CSP(n_components=4, transform_into='average_power')\n",
    "\n",
    "csp_data = csp.fit_transform(data.astype(np.float64),label)\n",
    "\n",
    "print(type(csp_data), csp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f432647",
   "metadata": {},
   "source": [
    "I have try various guess and I could found the way to fix this error. Therefore, I will aim toward what does the libry offer to you.\n",
    "\n",
    "The code will run if only use [:3650]\n",
    "\n",
    "Another knowledge I gain is the `mne.Epochs` convert data into `np.float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a87b81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1e+03 (2.2e-16 eps * 32 dim * 1.5e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.7e+02 (2.2e-16 eps * 32 dim * 1.2e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "<class 'numpy.ndarray'> (3650, 4)\n"
     ]
    }
   ],
   "source": [
    "csp = mne.decoding.CSP(n_components=4, transform_into='average_power')\n",
    "csp_data = csp.fit_transform(data.astype(np.float64)[:3650],label[:3650])\n",
    "print(type(csp_data), csp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee509a2",
   "metadata": {},
   "source": [
    "The result is another `numpy array` with shape (n_samples, n_components). The configuration above is actually the default parameters of `mnd.decoding.CSP`.\n",
    "\n",
    "The reason why we only have a single value of each component is that `transform_into` is set to `average_power`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0aa8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1e+03 (2.2e-16 eps * 32 dim * 1.5e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.7e+02 (2.2e-16 eps * 32 dim * 1.2e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "<class 'numpy.ndarray'> (3650, 4, 672)\n"
     ]
    }
   ],
   "source": [
    "csp = mne.decoding.CSP(n_components=4, transform_into='csp_space')\n",
    "csp_data = csp.fit_transform(data.astype(np.float64)[:3650],label[:3650])\n",
    "print(type(csp_data), csp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336607da",
   "metadata": {},
   "source": [
    "Now, that is more like it. The result is the same as performing PCA.\n",
    "\n",
    "However, CSP component (`n_components`) can only be determine using cross-validation (documented in the API).\n",
    "\n",
    "This means you can extract as many components as you like but it won't exceed the number of channels you have in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d81f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1e+03 (2.2e-16 eps * 32 dim * 1.5e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.7e+02 (2.2e-16 eps * 32 dim * 1.2e+17  max singular value)\n",
      "    Estimated rank (mag): 32\n",
      "    MAG: rank 32 computed from 32 data channels with 0 projectors\n",
      "Reducing data rank from 32 -> 32\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "<class 'numpy.ndarray'> (3650, 32, 672)\n"
     ]
    }
   ],
   "source": [
    "csp = mne.decoding.CSP(n_components=100, transform_into='csp_space')\n",
    "csp_data = csp.fit_transform(data.astype(np.float64)[:3650],label[:3650])\n",
    "print(type(csp_data), csp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9862ae",
   "metadata": {},
   "source": [
    "the data we obtained is a time-series data. Thus mean the followed task is spectral analysis. (well, it does not make sense to do asymmetry and connectivity since the data is no longer a brain region space anymore).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9e8f",
   "metadata": {},
   "source": [
    "## CSP with another Library\n",
    "\n",
    "https://github.com/spolsley/common-spatial-patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/spolsley/common-spatial-patterns\n",
    "\n",
    "# Common Spatial Pattern implementation in Python, used to build spatial filters for identifying task-related activity.\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# CSP takes any number of arguments, but each argument must be a collection of trials associated with a task\n",
    "# That is, for N tasks, N arrays are passed to CSP each with dimensionality (# of trials of task N) x (feature vector)\n",
    "# Trials may be of any dimension, provided that each trial for each task has the same dimensionality,\n",
    "# otherwise there can be no spatial filtering since the trials cannot be compared\n",
    "def CSP(*tasks):\n",
    "\tif len(tasks) < 2:\n",
    "\t\tprint(\"Must have at least 2 tasks for filtering.\")\n",
    "\t\treturn (None,) * len(tasks)\n",
    "\telse:\n",
    "\t\tfilters = ()\n",
    "\t\t# CSP algorithm\n",
    "\t\t# For each task x, find the mean variances Rx and not_Rx, which will be used to compute spatial filter SFx\n",
    "\t\titerator = range(0,len(tasks))\n",
    "\t\tfor x in iterator:\n",
    "\t\t\t# Find Rx\n",
    "\t\t\tRx = covarianceMatrix(tasks[x][0])\n",
    "\t\t\tfor t in range(1,len(tasks[x])):\n",
    "\t\t\t\tRx += covarianceMatrix(tasks[x][t])\n",
    "\t\t\tRx = Rx / len(tasks[x])\n",
    "\n",
    "\t\t\t# Find not_Rx\n",
    "\t\t\tcount = 0\n",
    "\t\t\tnot_Rx = Rx * 0\n",
    "\t\t\tfor not_x in [element for element in iterator if element != x]:\n",
    "\t\t\t\tfor t in range(0,len(tasks[not_x])):\n",
    "\t\t\t\t\tnot_Rx += covarianceMatrix(tasks[not_x][t])\n",
    "\t\t\t\t\tcount += 1\n",
    "\t\t\tnot_Rx = not_Rx / count\n",
    "\n",
    "\t\t\t# Find the spatial filter SFx\n",
    "\t\t\tSFx = spatialFilter(Rx,not_Rx)\n",
    "\t\t\tfilters += (SFx,)\n",
    "\n",
    "\t\t\t# Special case: only two tasks, no need to compute any more mean variances\n",
    "\t\t\tif len(tasks) == 2:\n",
    "\t\t\t\tfilters += (spatialFilter(not_Rx,Rx),)\n",
    "\t\t\t\tbreak\n",
    "\t\treturn filters\n",
    "\n",
    "# covarianceMatrix takes a matrix A and returns the covariance matrix, scaled by the variance\n",
    "def covarianceMatrix(A):\n",
    "\tCa = np.dot(A,np.transpose(A))/np.trace(np.dot(A,np.transpose(A)))\n",
    "\treturn Ca\n",
    "\n",
    "# spatialFilter returns the spatial filter SFa for mean covariance matrices Ra and Rb\n",
    "def spatialFilter(Ra,Rb):\n",
    "\tR = Ra + Rb\n",
    "\tE,U = la.eig(R)\n",
    "\n",
    "\t# CSP requires the eigenvalues E and eigenvector U be sorted in descending order\n",
    "\tord = np.argsort(E)\n",
    "\tord = ord[::-1] # argsort gives ascending order, flip to get descending\n",
    "\tE = E[ord]\n",
    "\tU = U[:,ord]\n",
    "\n",
    "\t# Find the whitening transformation matrix\n",
    "\tP = np.dot(np.sqrt(la.inv(np.diag(E))),np.transpose(U))\n",
    "\n",
    "\t# The mean covariance matrices may now be transformed\n",
    "\tSa = np.dot(P,np.dot(Ra,np.transpose(P)))\n",
    "\tSb = np.dot(P,np.dot(Rb,np.transpose(P)))\n",
    "\n",
    "\t# Find and sort the generalized eigenvalues and eigenvector\n",
    "\tE1,U1 = la.eig(Sa,Sb)\n",
    "\tord1 = np.argsort(E1)\n",
    "\tord1 = ord1[::-1]\n",
    "\tE1 = E1[ord1]\n",
    "\tU1 = U1[:,ord1]\n",
    "\n",
    "\t# The projection matrix (the spatial filter) may now be obtained\n",
    "\tSFa = np.dot(np.transpose(U1),P)\n",
    "\treturn SFa.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42288966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> (32, 32) (32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17619/3811170600.py:78: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return SFa.astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "filters = CSP(data[label==0], data[label==1])\n",
    "print(type(filters), filters[0].shape, filters[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d6492",
   "metadata": {},
   "source": [
    "Ah ha, I have not yet given up. I search for other library and here we are continue to code. Sorry fork. You stuck with me for a bit longer.\n",
    "\n",
    "As you can see, this library calculate the filter base on the given data. We will you the filter to convert from `brain region space` to `csp-space`.\n",
    "\n",
    "The filter will need to be used base on the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0395afeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 672)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[0].T @ filters[label[0].astype(int)]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d0a906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711cb906b9d241798507c33becd57022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15360, 32, 672)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "csp_data = []\n",
    "for index in tqdm(range(len(data))):\n",
    "    \n",
    "    # (672, 32) @ (32, 32) = (672, 32)\n",
    "    csp = data[index].T @ filters[label[index].astype(int)]\n",
    "    # (1, 32, 672)\n",
    "    csp = np.expand_dims(csp.T, axis=0)\n",
    "    csp_data.append(csp)\n",
    "\n",
    "csp_data = np.vstack(csp_data)\n",
    "print(csp_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e47fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n",
      "/root/projects/.venv/lib/python3.8/site-packages/mne_features/mock_numba.py:12: UserWarning: Numba needs NumPy 1.21 or less. Your code will be slower.\n",
      "  warn('{}. Your code will be slower.'.format(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15360, 160) 66.80781841278076\n"
     ]
    }
   ],
   "source": [
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "bands = [(0,4), (4,8), (8,12), (12,30), (30,64)]\n",
    "# [alias_feature_function]__[optional_param]\n",
    "params = dict({\n",
    "    'pow_freq_bands__log':True,\n",
    "    'pow_freq_bands__normalize':False,\n",
    "    'pow_freq_bands__freq_bands':bands\n",
    "})\n",
    "fe = FeatureExtractor(sfreq=128, selected_funcs=['pow_freq_bands'],params=params,n_jobs=8)\n",
    "X = fe.fit_transform(X=csp_data)\n",
    "print(X.shape, time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02b41d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKernel=linear| Acc=0.64616 | 3-CV score=0.70352 STD=0.03324| Time spend=73.69449186325073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/root/projects/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKernel=poly| Acc=0.45228 | 3-CV score=0.56914 STD=0.11847| Time spend=7.272881507873535\n",
      "\tKernel=rbf| Acc=0.67826 | 3-CV score=0.67357 STD=0.00033| Time spend=139.15341567993164\n",
      "\tKernel=sigmoid| Acc=0.55312 | 3-CV score=0.55312 STD=0.0| Time spend=105.43437027931213\n"
     ]
    }
   ],
   "source": [
    "def train_model(X_ori,y_ori, kernel='rbf'):\n",
    "    # Make a copy because I am paranoid\n",
    "    X,y = X_ori.copy(), y_ori.copy()\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # \n",
    "    X_shuff,y_shuff = shuffle(X,y)\n",
    "    model = SVC(kernel=kernel,max_iter=10000)\n",
    "    cross = cross_val_score(model, X_shuff, y_shuff, cv=3)\n",
    "\n",
    "    model = SVC(kernel=kernel, max_iter=10000)\n",
    "    model.fit(X_shuff, y_shuff)\n",
    "    ans = model.predict(X_shuff)\n",
    "    acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "    return model, acc, cross\n",
    "\n",
    "for kernel in ['linear','poly','rbf', 'sigmoid']:\n",
    "    start = time.time()\n",
    "    model, acc, cross = train_model(X, label, kernel=kernel)\n",
    "    # We can save the model and reuse it later\n",
    "    print(f\"\\tKernel={kernel}| Acc={round(acc,5)} | 3-CV score={round(cross.mean(),5)} STD={round(cross.std(),5)}| Time spend={time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82432ad",
   "metadata": {},
   "source": [
    "Okay, the result is not very pleasing. However, we did use all 32 csp components. As suggested by the mne folk, we should play around with the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f06ef4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15360, 4, 672)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csp_data[:,:4,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16963b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_component=1\n",
      "(15360, 5) 82.39137411117554\n",
      "\tKernel='rbf'| Acc=0.67435 | 3-CV score=0.67188 STD=0.00295| Time spend=30.879997491836548\n",
      "--------------------\n",
      "n_component=2\n",
      "(15360, 10) 38.85746693611145\n",
      "\tKernel='rbf'| Acc=0.6748 | 3-CV score=0.67109 STD=0.00804| Time spend=33.660973072052\n",
      "--------------------\n",
      "n_component=3\n",
      "(15360, 15) 40.304635524749756\n",
      "\tKernel='rbf'| Acc=0.6748 | 3-CV score=0.67285 STD=0.00732| Time spend=38.41354560852051\n",
      "--------------------\n",
      "n_component=4\n",
      "(15360, 20) 44.97115874290466\n",
      "\tKernel='rbf'| Acc=0.67454 | 3-CV score=0.67161 STD=0.00369| Time spend=37.92103624343872\n",
      "--------------------\n",
      "n_component=5\n",
      "(15360, 25) 44.849576234817505\n",
      "\tKernel='rbf'| Acc=0.67786 | 3-CV score=0.67409 STD=0.00113| Time spend=43.60341739654541\n",
      "--------------------\n",
      "n_component=6\n",
      "(15360, 30) 50.73816728591919\n",
      "\tKernel='rbf'| Acc=0.67754 | 3-CV score=0.67285 STD=0.0036| Time spend=50.42497944831848\n",
      "--------------------\n",
      "n_component=7\n",
      "(15360, 35) 57.738218784332275\n",
      "\tKernel='rbf'| Acc=0.67799 | 3-CV score=0.67487 STD=0.00295| Time spend=46.1234872341156\n",
      "--------------------\n",
      "n_component=8\n",
      "(15360, 40) 53.9074125289917\n",
      "\tKernel='rbf'| Acc=0.67786 | 3-CV score=0.67448 STD=0.00115| Time spend=58.03658890724182\n",
      "--------------------\n",
      "n_component=9\n",
      "(15360, 45) 66.53843259811401\n",
      "\tKernel='rbf'| Acc=0.67734 | 3-CV score=0.67415 STD=0.00217| Time spend=61.47254824638367\n",
      "--------------------\n",
      "n_component=10\n",
      "(15360, 50) 70.41190671920776\n",
      "\tKernel='rbf'| Acc=0.67682 | 3-CV score=0.67279 STD=0.00273| Time spend=53.66869378089905\n",
      "--------------------\n",
      "n_component=11\n",
      "(15360, 55) 62.82732701301575\n",
      "\tKernel='rbf'| Acc=0.67721 | 3-CV score=0.67344 STD=0.00162| Time spend=62.13468265533447\n",
      "--------------------\n",
      "n_component=12\n",
      "(15360, 60) 71.12687492370605\n",
      "\tKernel='rbf'| Acc=0.67741 | 3-CV score=0.67422 STD=0.00437| Time spend=72.28953146934509\n",
      "--------------------\n",
      "n_component=13\n",
      "(15360, 65) 83.30876016616821\n",
      "\tKernel='rbf'| Acc=0.67734 | 3-CV score=0.67441 STD=0.00491| Time spend=66.12864208221436\n",
      "--------------------\n",
      "n_component=14\n",
      "(15360, 70) 75.95702695846558\n",
      "\tKernel='rbf'| Acc=0.67754 | 3-CV score=0.67454 STD=0.00663| Time spend=82.29950141906738\n",
      "--------------------\n",
      "n_component=15\n",
      "(15360, 75) 91.70827865600586\n",
      "\tKernel='rbf'| Acc=0.67721 | 3-CV score=0.67376 STD=0.00265| Time spend=80.27802991867065\n",
      "--------------------\n",
      "n_component=16\n",
      "(15360, 80) 90.19196391105652\n",
      "\tKernel='rbf'| Acc=0.67721 | 3-CV score=0.6735 STD=0.00432| Time spend=75.2559928894043\n",
      "--------------------\n",
      "n_component=17\n",
      "(15360, 85) 85.49836230278015\n",
      "\tKernel='rbf'| Acc=0.67741 | 3-CV score=0.67376 STD=0.0062| Time spend=92.77137613296509\n",
      "--------------------\n",
      "n_component=18\n",
      "(15360, 90) 105.38374996185303\n",
      "\tKernel='rbf'| Acc=0.67747 | 3-CV score=0.67402 STD=0.00263| Time spend=90.84117221832275\n",
      "--------------------\n",
      "n_component=19\n",
      "(15360, 95) 101.58129096031189\n",
      "\tKernel='rbf'| Acc=0.67721 | 3-CV score=0.67357 STD=0.00734| Time spend=99.90022492408752\n",
      "--------------------\n",
      "n_component=20\n",
      "(15360, 100) 110.5093731880188\n",
      "\tKernel='rbf'| Acc=0.67734 | 3-CV score=0.67467 STD=0.00374| Time spend=96.06916236877441\n",
      "--------------------\n",
      "n_component=21\n",
      "(15360, 105) 107.74389433860779\n",
      "\tKernel='rbf'| Acc=0.67715 | 3-CV score=0.67435 STD=0.00654| Time spend=94.7903482913971\n",
      "--------------------\n",
      "n_component=22\n",
      "(15360, 110) 106.4474105834961\n",
      "\tKernel='rbf'| Acc=0.67715 | 3-CV score=0.67487 STD=0.00453| Time spend=114.54529023170471\n",
      "--------------------\n",
      "n_component=23\n",
      "(15360, 115) 128.33081007003784\n",
      "\tKernel='rbf'| Acc=0.67734 | 3-CV score=0.67415 STD=0.0027| Time spend=113.58027148246765\n",
      "--------------------\n",
      "n_component=24\n",
      "(15360, 120) 125.59179925918579\n",
      "\tKernel='rbf'| Acc=0.67741 | 3-CV score=0.6737 STD=0.00572| Time spend=117.90454149246216\n",
      "--------------------\n",
      "n_component=25\n",
      "(15360, 125) 130.91819596290588\n",
      "\tKernel='rbf'| Acc=0.67819 | 3-CV score=0.67337 STD=0.00699| Time spend=142.70827198028564\n",
      "--------------------\n",
      "n_component=26\n",
      "(15360, 130) 156.97211909294128\n",
      "\tKernel='rbf'| Acc=0.67812 | 3-CV score=0.67344 STD=0.00146| Time spend=162.44581031799316\n",
      "--------------------\n",
      "n_component=27\n",
      "(15360, 135) 177.68645405769348\n",
      "\tKernel='rbf'| Acc=0.67845 | 3-CV score=0.67454 STD=0.00309| Time spend=175.62604212760925\n",
      "--------------------\n",
      "n_component=28\n",
      "(15360, 140) 190.8748824596405\n",
      "\tKernel='rbf'| Acc=0.67819 | 3-CV score=0.67435 STD=0.00782| Time spend=182.72256112098694\n",
      "--------------------\n",
      "n_component=29\n",
      "(15360, 145) 198.30050778388977\n",
      "\tKernel='rbf'| Acc=0.67832 | 3-CV score=0.67533 STD=0.00152| Time spend=189.516503572464\n",
      "--------------------\n",
      "n_component=30\n",
      "(15360, 150) 205.26897168159485\n",
      "\tKernel='rbf'| Acc=0.67819 | 3-CV score=0.67415 STD=0.00654| Time spend=189.73826456069946\n",
      "--------------------\n",
      "n_component=31\n",
      "(15360, 155) 205.1304907798767\n",
      "\tKernel='rbf'| Acc=0.67839 | 3-CV score=0.67396 STD=0.00768| Time spend=189.53823161125183\n",
      "--------------------\n",
      "n_component=32\n",
      "(15360, 160) 207.48369121551514\n",
      "\tKernel='rbf'| Acc=0.67826 | 3-CV score=0.6763 STD=0.00443| Time spend=169.93545246124268\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for n_component in range(1,32+1):\n",
    "    print(f'{n_component=}')\n",
    "    bands = [(0,4), (4,8), (8,12), (12,30), (30,64)]\n",
    "    # [alias_feature_function]__[optional_param]\n",
    "    params = dict({\n",
    "        'pow_freq_bands__log':True,\n",
    "        'pow_freq_bands__normalize':False,\n",
    "        'pow_freq_bands__freq_bands':bands\n",
    "    })\n",
    "    fe = FeatureExtractor(sfreq=128, selected_funcs=['pow_freq_bands'],params=params,n_jobs=8)\n",
    "\n",
    "    ##### Here I select component #####\n",
    "    X = fe.fit_transform(X=csp_data[:,:n_component,:])\n",
    "    print(X.shape, time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    model, acc, cross = train_model(X, label, kernel='rbf')\n",
    "    # We can save the model and reuse it later\n",
    "    print(f\"\\tKernel='rbf'| Acc={round(acc,5)} | 3-CV score={round(cross.mean(),5)} STD={round(cross.std(),5)}| Time spend={time.time() - start}\")\n",
    "    print('----'*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360921d",
   "metadata": {},
   "source": [
    "After the comprehensive run, I am a bit disappointed that I could not get the result higher than 67% accuracy. Below I re-run the spectral analysis from the `brain region space` data and confirm that it achieves a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d1ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15360, 160) 209.67438411712646\n",
      "\tKernel='rbf'| Acc=0.70436 | 3-CV score=0.67344 STD=0.00361| Time spend=189.62864065170288\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "bands = [(0,4), (4,8), (8,12), (12,30), (30,64)]\n",
    "# [alias_feature_function]__[optional_param]\n",
    "params = dict({\n",
    "    'pow_freq_bands__log':True,\n",
    "    'pow_freq_bands__normalize':False,\n",
    "    'pow_freq_bands__freq_bands':bands\n",
    "})\n",
    "fe = FeatureExtractor(sfreq=128, selected_funcs=['pow_freq_bands'],params=params,n_jobs=8)\n",
    "\n",
    "##### Here I select component #####\n",
    "X = fe.fit_transform(X=data)\n",
    "print(X.shape, time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "model, acc, cross = train_model(X, label, kernel='rbf')\n",
    "# We can save the model and reuse it later\n",
    "print(f\"\\tKernel='rbf'| Acc={round(acc,5)} | 3-CV score={round(cross.mean(),5)} STD={round(cross.std(),5)}| Time spend={time.time() - start}\")\n",
    "print('----'*5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
