{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. DEAP Dataset + Common Spatial Pattern + SVM\n",
    "\n",
    "In this part 5, we will focus on performing feature engineering using common spatial pattern analysis.  Common spatial pattern is about separating signals into additive composed components that has the maximium differences in variances.\n",
    "\n",
    "Common spatial pattern is a very common dimensionality reduction techniques done on EEG signals.  The main difference between CSP and LDA is that CSP does not look at mean.  On the other hand, CSP is extremely similar to PCA (Principle Component Analysis) because it also employs eigenvalue decompositions but the slight difference is that CSP is done on two different signal windows thus you can say that CSP is a PCA made specificially for signals.\n",
    "\n",
    "In this part, we shall extract common spatial patterns as features.  Lastly, let's try input the features into SVM and see if these features are useful for predicting the four valence-arousal classes that we have obtained from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cuda accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset\n",
    "\n",
    "Let's first reuse the dataset loader we have created in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, stim):\n",
    "        _, _, filenames = next(os.walk(path))\n",
    "        filenames = sorted(filenames)\n",
    "        all_data = []\n",
    "        all_label = []\n",
    "        for dat in filenames:\n",
    "            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n",
    "            all_data.append(temp['data'])\n",
    "            \n",
    "            if stim == \"Valence\":\n",
    "                all_label.append(temp['labels'][:,:1])   #the first index is valence\n",
    "            elif stim == \"Arousal\":\n",
    "                all_label.append(temp['labels'][:,1:2]) # Arousal  #the second index is arousal\n",
    "                \n",
    "        self.data = np.vstack(all_data)[:, :32, ]   #shape: (1280, 32, 8064) --> take only the first 32 channels\n",
    "        \n",
    "        shape = self.data.shape\n",
    "        \n",
    "        #perform segmentation=====\n",
    "        segments = 12\n",
    "        \n",
    "        self.data = self.data.reshape(shape[0], shape[1], int(shape[2]/segments), segments)\n",
    "        #data shape: (1280, 32, 672, 12)\n",
    "\n",
    "        self.data = self.data.transpose(0, 3, 1, 2)\n",
    "        #data shape: (1280, 12, 32, 672)\n",
    "\n",
    "        self.data = self.data.reshape(shape[0] * segments, shape[1], -1)\n",
    "        #data shape: (1280*12, 32, 672)\n",
    "        #==========================\n",
    "        \n",
    "        self.label = np.vstack(all_label) #(1280, 1)  ==> 1280 samples, \n",
    "        self.label = np.repeat(self.label, 12)[:, np.newaxis]  #the dimension 1 is lost after repeat, so need to unsqueeze (1280*12, 1)\n",
    "        \n",
    "        del temp, all_data, all_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        single_data  = self.data[idx]\n",
    "        single_label = (self.label[idx] > 5).astype(float)   #convert the scale to either 0 or 1 (to classification problem)\n",
    "        \n",
    "        batch = {\n",
    "            'data': torch.Tensor(single_data),\n",
    "            'label': torch.Tensor(single_label)\n",
    "        }\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data\"  #create a folder \"data\", and inside put s01.dat,....,s32.dat inside from the preprocessed folder from the DEAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  torch.Size([15360, 32, 672])\n",
      "Label shape:  torch.Size([15360, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(path, \"Valence\")\n",
    "\n",
    "data  = dataset[:]['data']\n",
    "label = dataset[:]['label']\n",
    "\n",
    "print(\"Data shape: \" , data.shape)  #15360 = 32 * 40 trials * 12 segments, 32 EEG channels, 672 samples\n",
    "print(\"Label shape: \", label.shape)  #two classes of valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connectivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
